{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fetch_prices(tickers):\n",
    "    files = [f'./data/processed/{asset}.csv' for asset in tickers]\n",
    "    asset_data = [pd.read_csv(file) for file in files]\n",
    "    benchmark_data = pd.read_csv('./data/djia.csv')\n",
    "    return asset_data, benchmark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_observe = ['close','Return_1d_stock','Return_3d_stock','Return_5d_stock','Return_10d_stock','Return_50d_stock','Return_100d_stock','Return_1d_Correlation','Return_3d_Correlation','Return_5d_Correlation','Return_10d_Correlation','Return_50d_Correlation','Return_100d_Correlation','ADX','Aroon_Up','Aroon_Down','CCI','EMA','KAMA','ROC','RSI','CMF','ADI','FI','Bollinger_high','Bollinger_low','Donchian_low','Donchian_high']\n",
    "\n",
    "def fetch_observations(assets:list[pd.DataFrame],benchmark:pd.DataFrame,period,start_date,end_date):\n",
    "    assets = [asset[(asset['date'] >= start_date) & (asset['date'] <= end_date)] for asset in assets]\n",
    "    benchmark = benchmark[(benchmark['date'] >= start_date) & (benchmark['date'] <= end_date)]\n",
    "    prices = [asset['close'].iloc[::period].values for asset in assets]\n",
    "    \n",
    "    prices_array = np.array(prices,dtype=np.float32).T\n",
    "    benchmark_array = np.array(benchmark['close'].iloc[::period].values,dtype=np.float32)\n",
    "    \n",
    "    observations = []\n",
    "    for asset in assets:\n",
    "        asset_obs = []\n",
    "        for column in columns_to_observe:\n",
    "            asset_obs.append(np.array(asset[column].shift(1).dropna().iloc[::period].values,dtype=np.float32)) # shift by 1 to avoid look-ahead bias\n",
    "            \n",
    "        observations.append(asset_obs)\n",
    "        \n",
    "    observations_array = np.array(observations).transpose(2, 0, 1)\n",
    "    return prices_array, benchmark_array, observations_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces,Env\n",
    "import numpy as np\n",
    "\n",
    "ACTION_BOUND = 6\n",
    "\n",
    "class PortfolioEnv(Env):\n",
    "    def __init__(self, observation_timeline:np.ndarray, data_timeline:np.ndarray, benchmark_timeline:np.ndarray, investment_period=3,reward_period=10,risk_aversion=0.5):\n",
    "        self.num_of_assets = data_timeline.shape[1]\n",
    "        self.investment_freq = investment_period\n",
    "        self.reward_freq = reward_period\n",
    "        self.risk_aversion = risk_aversion\n",
    "        \n",
    "        self.observation_timeline = observation_timeline\n",
    "        self.data_timeline = data_timeline\n",
    "        self.benchmark_timeline = benchmark_timeline\n",
    "        \n",
    "        self.action_space = spaces.Box(low=0, high=ACTION_BOUND, shape=(self.num_of_assets+1,)) # +1 for cash\n",
    "        \n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_of_assets*len(columns_to_observe),))\n",
    "        \n",
    "        self.portfolio_returns:list[float] = []\n",
    "        self.benchmark_returns:list[float] = []\n",
    "        \n",
    "        self.current_step = 0\n",
    "        self.current_worth = 1.0\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self,seed=None):\n",
    "        self.current_step = 0\n",
    "        return self.get_observation(),{}\n",
    "    \n",
    "    def step(self,action):\n",
    "        self.calculate_asset_returns(action)\n",
    "        self.calculate_benchmark_returns()\n",
    "        \n",
    "        done = False\n",
    "        reward = 0.0\n",
    "        if (self.current_step + 1) % self.reward_freq == 0:\n",
    "            reward = self.calculate_reward()\n",
    "            \n",
    "        self.current_step += 1\n",
    "        \n",
    "        if self.current_step >= len(self.data_timeline)-1:\n",
    "            done = True\n",
    "            self.current_step = 0\n",
    "        \n",
    "        return self.get_observation(), reward, done,False , {}\n",
    "    \n",
    "    def get_observation(self):\n",
    "        return self.observation_timeline[self.current_step].flatten()\n",
    "        \n",
    "\n",
    "    def calculate_asset_returns(self,action):\n",
    "        weights = self.calculate_weights(action)\n",
    "        asset_wise_returns = np.zeros(self.num_of_assets+1)\n",
    "        asset_wise_returns[:-1] = self.data_timeline[self.current_step+1]/self.data_timeline[self.current_step]\n",
    "        asset_wise_returns[-1] = 1 # cash\n",
    "        \n",
    "        portfolio_return = np.dot(weights.T,asset_wise_returns)\n",
    "        self.current_worth *= portfolio_return\n",
    "        self.portfolio_returns.append(np.log(portfolio_return))\n",
    "        \n",
    "    def calculate_weights(self,action):\n",
    "        exp_action = np.exp(action)\n",
    "        weights = exp_action/np.sum(exp_action)\n",
    "        return np.round(weights,4)\n",
    "    \n",
    "    def calculate_benchmark_returns(self):\n",
    "        self.benchmark_returns.append(np.log(self.benchmark_timeline[self.current_step+1]/self.benchmark_timeline[self.current_step]))\n",
    "        \n",
    "    def calculate_reward(self):\n",
    "        diff = np.array(self.portfolio_returns) - np.array(self.benchmark_returns)\n",
    "        mean_diff = np.mean(diff)\n",
    "        var_diff = np.var(diff)\n",
    "        corr = np.cov(self.portfolio_returns,self.benchmark_returns)[0,1]/(np.std(self.portfolio_returns)*np.std(self.benchmark_returns))\n",
    "        \n",
    "        self.portfolio_returns = []\n",
    "        self.benchmark_returns = []\n",
    "        \n",
    "        return mean_diff - self.risk_aversion*(var_diff/(1-corr))\n",
    "    \n",
    "    def render(self):\n",
    "        print(f\"Step: {self.current_step}, Prices: {self.data_timeline[self.current_step]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "tickers = ['AAPL','JPM','F']\n",
    "\n",
    "assets,benchmark = fetch_prices(tickers)\n",
    "investment_period = 1 # each 3 investment days \n",
    "reward_period = 15 # each 10 investment periods\n",
    "data_timeline,benchmark_timeline,observation_timeline = fetch_observations(assets,benchmark,start_date='1992-01-01',end_date='2018-12-31',period=investment_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\.war\\satan\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:453: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "env = PortfolioEnv(observation_timeline=observation_timeline,data_timeline=data_timeline,benchmark_timeline=benchmark_timeline, reward_period=reward_period,investment_period=investment_period)\n",
    "\n",
    "check_env(env)\n",
    "\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Using cpu device\n",
      "Using cpu device\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import  PPO, A2C, SAC, DDPG\n",
    "from stable_baselines3.common.base_class import BaseAlgorithm\n",
    "models_to_train: list[BaseAlgorithm] = [\n",
    "    SAC('MlpPolicy', env, verbose=1,learning_rate=0.0005),\n",
    "    DDPG('MlpPolicy', env, verbose=1,learning_rate=0.0005),\n",
    "    A2C('MlpPolicy', env, verbose=1,learning_rate=0.0005),\n",
    "    PPO('MlpPolicy', env, verbose=1,learning_rate=0.0005),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180099dcf1934630ab7c8185b41020dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in models_to_train:\n",
    "    model.learn(total_timesteps=100000,progress_bar=True)\n",
    "    model.save(f'./models/{model.__class__.__name__}_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model,env,prices,benchmark,observations):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    portfolio_values = [1]\n",
    "    rewards = []\n",
    "    \n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        portfolio_values.append(env.current_worth)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "    return portfolio_values, rewards\n",
    "\n",
    "\n",
    "eval_prices,eval_benchmark,eval_observations = fetch_observations(assets,benchmark,start_date='2019-01-01',end_date='2023-12-31',period=investment_period)\n",
    "\n",
    "for model in models_to_train:\n",
    "    model = model.load(f'./models/{model.__class__.__name__}_trained')\n",
    "    portfolio_values,rewards = evaluate_model(model,env,eval_prices,eval_benchmark,eval_observations)\n",
    "    model_name = model.__class__.__name__\n",
    "    plt.plot(portfolio_values,label=f'{model_name} portfolio values')\n",
    "    plt.twinx()\n",
    "    plt.plot(rewards, linestyle='dotted ',label=f'{model_name} rewards')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
